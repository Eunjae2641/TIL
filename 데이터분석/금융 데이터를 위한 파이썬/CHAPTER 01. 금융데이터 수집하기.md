#### CHAPTER 01.금융 데이터 수집하기

일반인이 인터넷을 통해 돈을 지급하지 않고 수집하는 방법으로 **파이썬 패키지, 오픈 API, 웹 크롤링**이 있다.

**파이썬 패키지**의 경우 수집 대상 즉, 범위가 좁은 대신 활용 난이도가 쉽다.
가장 쉽게 데이터를 수집하는 방법으로 보통 오픈 API로 제공되는 데이터를 쉽게 재구성한 패키지들이다. 
가장 대표적인 패키지로는 pandas-datareader가 있다.

**오픈 API**의 경우 범위도 중간, 활용 난이도도 중간이다.
금융 데이터를 수집하기 위해 가장 적절한 방법이지만 모든 데이터가 오픈API로 제공되지 않는다.
API란, Application Programming Interface의 약자로 해당 기능을 이용하여 다른 프로그램을 만들 수 있는 수준의 인터페이스를 제공하는 것을 말한다.
최근, 금융결제원을 통해 금융 관련 API가 많이 개방되고 있다. 데이터를 제공하는 것도 API로 구현된 곳이 많다. 
공공기관에서도 오픈 API를 통해 많은 데이터를 공개하고 있다. 공공 데이터 포털(www.data.go.kr)에 가면 개방된 데이터를 한 번에 볼 수 있다.

**웹 크롤링**의 경우 범위가 넓은 대신 활용 난이도가 어렵다.
웹에 있는 모든 데이터를 내 PC로 저장할 수 있다. 그래서 수집할 수 있는 범위가 가장 넓지만, HTML, CSS, 자바스크립트 등 웹에서 사용되는 기술에 대해 일부 알아야 한다. 웹 크롤링 방법도 여러 가지가 있다.
가장 많이 사용하는 방법으로는 **urllib 패키지 이용, 셀레늄(selenium) 이용, scrapy 패키지 이용**이 있습니다. 

**urllib 패키지 이용**은 범위가 좁고 활용 난이도가 쉽다.
파이썬으로 웹 크롤링할 때 가장 먼저 하는 방법이 urllib 패키지를 이용하는 것이지만, 동적으로 변하는 페이지를 크롤링하거나 자동화하기에 어려움이 있다.

**셀레늄(selenium) 패키지**는 웹 테스트 자동화를 위한 도구로, 파이썬 코드로 웹 브라우저를 조정할 수 있고 웹에서 할 수 있는 거의 모든 동작을 할 수 있어 매우 유용하다. 범위가 넓지만 활용 난이도가 어렵다.

**scrapy 패키지**는 크롤링을 위한 단계들이 미리 구조화되어 있어 많은 웹 페이지를 자주 수집할 떄 유용한 패키지이다. 범위도 중간, 활용 난이도도 중간.

### 1.1 파이썬 패키지를 이용하여 데이터 수집하기
pandas-datareader로 금융 데이터를 제공하는 여러 가지 사이트의 정보를 쉽게 수집한다. 또한, 국내 주식 데이터를 수집하는 finance-datareader가 있다.

## 1.1.1 pandas-datareader 이용하기
수집가능한 주요 데이터는 **주가 데이터, 주가 지수 데이터, 환율 데이터, 원자재 가격 데이터, 그 외 경제 지표 데이터**가 있다.

# 주가 데이터
pandas-datareader로 주가 데이터를 수집하는 방법으로는 **야후**와 **구글 파이낸스**가 대표적이다. 하지만 곧 없어질 에정이기에 이 책에서는 **tiingo**를 사용하여 해외 주가 데이터만 수집했다. 국내 주가 데이터는 **FinanceDataReader**를 이용해 받는다. 
**tiingo**를 이용하려면 API KEY를 발급 받아야한다. 구글 종목 코드를 입력해서 주가 데이터를 받아 보고, head 함수를 통해서 확인하는 코드다.
원하는 주식의 종목 코드를 알고 싶다면, tiingo나 야후 파이낸스에서 주식명으로 검색.
코드는 code 폴더의 financedata.ipynb를 참고.

# 주가 지수 데이터
코스피나 나스닥 같은 주가 지수 정보는 **Stooq**라는 곳에서 수집 가능하다. Stooq에 접속해서 원하는 주가 지수를 입력하면 코드 정보를 알 수 있다.
KOSPI를 검색하여 코스피 검색 지수 코드를 확인하고, 지수 변화를 그래프로 그리는 코드다.
코드는 code 폴더의 Stooq.ipynb를 참고.

# 환율 데이터
**Alpha Vantage**에서 환율 데이터에 대해 무료로 API KEY를 발급받아 수집할 수 있다. DATAREADER 함수를 이용해 실시간 환율을 받을 수 있다.
관련 코드는 code 폴더의 USDKRW.ipynb를 참고.
pandas-datareader 패키지는 실시간 환율 데이터만 수집할 수 있다. 기간별 환율 데이터를 수집하고 싶다면, 직접 수집해야한다.
API로 데이터를 수집하기 위해서는 urllib 패키지를 이용하여 url에 필요한 파라미터를 입력한 후 전송하면 그에 맞는 데이터가 회신된다. 
일별 환율 데이터를 수집하기 위해서 아래와 같이 url을 구성. 주별,월별 단위의 데이터도 수집이 가능하다.

API를 이용해서 데이터를 수집하는 방법은 1.2 OPEN API를 이용하여 데이터 수집하기 참조.
관련 코드는 code 폴더의 url.ipynb를 참고.

from_symbol에 USD를 to_symbol에 KRW를 입력하면 원달러 환율 데이터를 얻을 수 있다. 요청한 데이터는 json 형식으로 회신되어, json 패키지를 이용해서 딕셔너리 자료형으로 바꿔 준다. json은 데이터를 전달하기 위한 포맷의 하나로, 키와 값으로 이루어진다.

파이썬에서는 데이터 분석을 위해 판다스 패키지의 데이터 프레임을 많이 사용한다. 데이터 프레임은 행과 열로 이루어진 테이블 형태의 자료형으로 데이터 분석에 사용하기 위해 딕셔너리를 판다스 데이터 프레임으로 바뀌었다.

# 원자재 가격 데이터
**원자재 가격**은 미국 연방준비은행에서 관리하는 FRED(Federal Reserve Economic Data)에서 수집할 수 있다. 찾고 싶은 정보를 사이트(https://fred.stlouisfed.org/)에서 검색합니다. 원유 가격을 확인하기 위해 oil이라고 검색한다면 Crude Oil Prices:West Texas Intermediate(WTI)를 찾을 수 있고 DCOILWTICO처럼 코드도 알 수 있다.
관련 코드는 code 폴더의 fred.ipynb를 참고.

# 그 외 경제 지표 데이터
GDP나 인구수 같은 경제 지표도 pandas_datareader를 통해서 수집할 수 있다. 경제 지표를 수집할 수 있는 곳은 Econdb,Fred, World Bank, OECD, Enigma가 있다. 
**Econdb**는 90개 이상의 공식적인 통계기관으로 경제 데이터를 제공한다
**Fred**는 세인트루이스 연방준비은행에서 제공하는 미국 및 각국의 주요 경제 지표를 수집할 수 있다.
**World Bank**는 세계 은행에서 제공하는 경제 지표 데이터이다.
**OECD**는 OECD 국가 통계 자료이다.
**Enigma**는 Enigma 사이트에서 제공하는 공개 데이터 수집이 가능하다.

**World Bank**를 통해 각국의 GDP 정보를 수집하려면 데이터를 수집하는 국가 코드를 알아야 한다. 구글에서 korea iso code를 검색하면 한국의 국가 코드가 KOR임을 알 수 있다.

World Bank에서 제공하는 데이터는 search 함수를 이용해서 데이터 코드를 검색할 수 있다. 제일 앞에서 수집하려는 경제 지표를 입력하고, 마침표로 검색하려는 상세 내용을 입력해야 한다 

관련 코드는 code 폴더의 GDP.ipynb를 참고.

한국과 일본의 구매력 기준 1인당 국민 소득을 그래프로 그렸다.
관련 코드는 code 폴더의 KOGDP.ipynb를 참고.

## 1.1.2 finance-datareader 이용하기
pandas-datareader의 장점은 편리하게 금융 데이터를 수집할 수 있다는 것이다. 하지만 국내 주식 데이터를 수집하기에는 다소 어려움이 있다.
국내 주식 데이터는 **FinanceDataReader**라는 패키지를 통해 수집할 수 있다.

**FinanceDataReader**는 'pip install finance-datareader'를 입력하면 설치할 수 있다.

# 전체 종목 코드 수집하기
**StockListing**이라는 함수를 이용하면 전체 종목 코드를 수집할 수 있다. 한국과 미국의 종목 코드를 모두 수집할 수 있다. 한국은 KRX(KRX 종목 전체), KOSPI, KOSDA, KONEX를 입력하고, 미국은 NASDAQ, NYSE(뉴욕 증권거래소 종목), AMEX(AMEX 종목), SP500을 입력하면 된다.
관련 코드는 code 폴더의 KOSPI.ipynb를 참고.

# 국내 주가 데이터 수집하기
수집한 데이터에서 삼성전자 종목 코드를 확인하는 코드.
관련 코드는 code 폴더의 samsung.ipynb를 참고.

삼성전자 주가를 수집하여 종가 추이를 확인하는 코드.
관련 코드는 code 폴더의 samsungplus.ipynb를 참고.

finance datareader에서도 각종 지수와 환율 데이터, 암호화 화폐 가격 데이터를 수집할 수 있다. 
finance datareader 사이트 참고.

### 1.2 OPEN API를 이용하여 데이터 수집하기
**OPEN API**는 누구나 사용할 수 있는 공개된 API를 말한다. API는 'Application Programming Interface'의 약자로, 특정 기능을 다른 프로그램에서 사용할 수 있도록 제공하는 인터페이스이다. 데이터를 제공하는 방법으로 API를 이용하기도 한다. 

공공 데이터 포탈에서는 여러 공공 기관이 공개해 놓은 데이터를 확인할 수 있습니다. 이 중에 많은 데이터를 OPEN API로 수집할 수 있습니다.
그중에서도 경제와 금융 관련된 것들을 확인해 보면 하단과 같습니다.

경제·금융 관련 공공 데이터 (하단에서 지칭하는 공공 포털을 공공 데이터 포털을 지칭한다.)
> 국가 재정 : 공공 포털, KOSIS에서 제공하며 세금, 국채, 채무 등을 제공한다.
> 인구/가구 : KOSIS에서 제공하며 인구수, 생명표, 가구수 등을 제공한다.
> 경기/기업 경영 : 공공 포털, KOSIS, 한국은행에서 제공하며 기업 경영, 경기 동향 등을 제공한다.
> 국토 관리 : 공공 포털, KOSIS, 국토교통부에서 제공하며 건축/건설, 부동산, 수자원, 국토 정보 등을 제공한다. 
> 물가/가게 : 공공 포털, KOSIS, 한국은행에서 제공하며 통화/유동성 등을 제공한다.
> 금리/환율 : 공공 포털, 은행연합회, 한국은행에서 제공하며 기준금리, 예금금리, 대출금리, 환율 등을 제공한다.
> 주식/채권 : 공공 포털, 한국거래소에서 제공하며 주가지수, 채권지수, 파생상품지수 등을 제공한다.
> 무역/국제 수지 : 공공 포털, KOSIS에서 제공하며 무역, 국제수지 등을 제공한다.

공공 데이터 포털에서 '부동산 실거래가'를 조회하면 국토교통부 실거래가 정보를 찾을 수 있다.
그 정보를 클릭하면 총 12개 데이터가 OPEN API로 공개된 것을 알 수 있다.
그 중 상업 업무용 부동산 매매 데이터를 수집하려면 로그인을 하고 데이터 서비스 활용 버튼을 클릭하면 개발 계정을 신청할 수 있다.
개발 계정을 등록하기 위해 시스템 유형, 활용 정보, 상세 기능 정보 등을 입력해야 한다.
공공 데이터를 어떤 목적으로 활용하는지 파악하기 위한 설문 성격의 데이터이기에 자신의 사용 목적에 맞는 항목으로 적당히 입력한다.

개발 계정으로 신청하고 나면 심의 후 API키가 발급된다. 상업 업무용 부동산 매매 데이터는 자동 승인으로 신청하자마자 API키를 확인할 수 있다.
마이페이지 - OPEN API - 개발 계정 메뉴에서 신청한 항목을 클릭하면 일반 인증키를 확인할 수 있다.

상세 기능 정보 항목을 통해 미리보기 버튼을 클릭하면 데이터를 잘 수집할 수 있는지 확인할 수 있다.

servicekey에 발급받은 인증키를 넣고 미리보기 버튼을 클릭하면 잘 수집되는 것을 웹 브라우저에서 확인할 수 있다.
하지만 '99SERVICE ACCESS DENIED ERROR'라는 에러가 발생하면, 1시간 정도 기다린 후 다시 해보는 것이 좋다.
> API 사용 신청 정보가 공공 데이터 포털에서 해당 데이터를 제공하는 기관에 전달되어야 하는데, 1시간 단위로 전달되기 때문이다.

또한 정상적으로 입력하였는데도 미리보기가 되지 않는다면 URL을 직접 생성하여 웹 브라우저에 입력한다.
웹 브라우저에 요청할 때는 UTF-8이 아닌 URL 인코딩으로 입력해야하며 quote 함수를 통해 URL 인코딩으로 변경할 수 있다.
> from urllib.parse import quote
> url_new=quote(url)

데이터 수집을 확인하였으니 파이썬 코드로 데이터를 수집할 수 있도록 작성한다.

먼저, URL을 구성한다. URL은 미리보기를 한 웹 브라우저의 URL 창을 이용하는 것이 편리합니다. 
데이터 수집을 위한 URL은 보통 '기본 URL 주소 ? 입력 파라미터1=입력값 & 입력 파라미터2=입력값 & 입력 파라미터3=입력값...' 으로 이루어져 있습니다. 
우리가 미리보기를 한 URL에도 serviceKey,LAWD_CD,DEAL_YWD의 세 가지 입력 파라미터가 있습니다. 
순서대로 인증키, 지역 코드, 거래 연월을 입력하면됩니다. 지역 코드는 우편번호와 다른 지역을 분리하는 코드입니다.

파이썬에서 인터넷을 연결하기 위해서 urllib 패키지를 사용한다. urlopen 함수를 이용하면, 지정한 URL과 소켓 통신을 할 수 있도로고 자동 연결해준다.
관련 코드는 code 폴더의 internet.ipynb를 참고.

read 함수를 이용하면 수신한 데이터를 확인할 수 있다. xml 포맷으로 데이터를 수집할 수 있다.
관련 코드는 code 폴더의 xml.ipynb를 참고.

xml 데이터에서 원하는 내용을 추출하기 위해서 BeautifulSoup라는 패키지를 이용합니다.
BeautifulSoup는 HTML이나 XML 코드에서 원하는 데이터를 추출할 수 있도록 도와주는 패키지다.
BeautifulSoup는 파이썬 아나콘다 배포판에 포함되지 않아 별도로 설치해야 한다.
명령 프롬프트나 터미널 창에서 'pip install beautifulsoup4'를 입력하면 설치할 수 있다.
사용할 때는 bs4로 입력하는데, 설치할 때는 beautifulsoup4로 입력해야 해서 헷갈릴 수 있다.

BeautifulSoup를 이용할 때는 어떤 방식으로 분석할지 방법을 지정해야한다.
html 파일은 'html.parser'를, xml인 경우에는 'lxml-xml'을 이용하면된다.
어떤 방법들이 있믄지 더 궁금하다면, BeautifulSoup 공식 홈페이지를 찾아보면 좋다.

파싱하고 나면 바이트로 이루어진 한글도 텍스트로 확인 가능하다.
관련 코드는 code 폴더의 bs4.ipynb를 참고.

xml의 데이터는 태그로 이루어져 있다.
우리가 원하는 데이터는 item이라는 태그가 있다.
필요한 태그의 데이터를 추출하기 위해 findAll 함수를 사용한다.
findAll은 입력한 태그가 있는 모든 정보를 찾아 줍니다.
len 함수를 이용하여 총 35개의 데이터가 있는 것을 확인할 수 있다.
관련 코드는 code 폴더의 item.ipynb를 참고.

item 태그가 있는 데이터만 추렸다면 이제 for문을 이용해서 사용하려는 데이터를 레이아웃에 맞게 정리한다.
각각의 item 태그에는 건별로 거래 금액, 건물 면적, 건물 주용도 등의 데이터가 들어 있습니다.
각각의 태그 정보를 추출하여 리스트 자료형으로 정리할 수 있다.

tqdm 패키지를 이용하면 진행 상태를 쉽게 확인할 수 있다.
for문의 in 에 해당하는 객체에 tqdm 함수를 적용하기만 하면 된다.
관련 코드는 code 폴더의 tqdm.ipynb를 참고.


```<참고자료> 금융 데이터를 위한 파이썬(작가 테리엇)```